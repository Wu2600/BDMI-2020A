# 第十三周小结
---
## 循环网络
* 基本循环网络：反馈连接、权重共享
  * 训练：通过时间反向传播(BPTT)、不能并行化

    ​            梯度截断——设置梯度最大值

  * 变种：LSTM——收敛快，GRU——比LSTM计算成本低，双向RNN

* 长短时记忆网络（LSTM）
  * 门结构
  * 网络结构：遗忘门、输入门、输出门
  * GRU：合并LSTM中的隐状态c和h：更新门、重置门
  
* 序列对序列模型：Seq2Seq：两个并列LSTM；注意力机制；Transformer模型

* 循环网络的扩展：神经图灵机
## Tensorflow2 Keras-RNN
* 多层神经网络
* 卷积网络的基本结构
  * 卷积核和卷积运算：无填充/有填充——边缘补零，输出大小不变
  * 下采样层：缩小输出，有最大池化、平均池化等方法
  * 归一化层：如LCN，减去平均值、除以标准差
  * 卷积网络的层间连接：局部规则连接，利用图像的局部和谐性
* 人脸辨识与识别——特征学习
* 计算机视觉：对象检测、自动驾驶等，如R-CNN

## Tensorflow2 Keras-数据流水线
* Simple RNN
  * rnn=layers.RNN(layers.SimpleRNNCell(4))
  * outputs=rnn(inputs)
* Bidirectional
  * model.add(Bidirectional(LSTM(10)),input_shape)
* LSTM
  * rnn=layers.RNN(layers.LSTMCell(4))
* GRU
  * rnn=layers.RNN(layers.GRUCell(4))
* 清除状态：rnn.reset_states()
* 状态重用
  * output=layer(inputs,initial_state=existing_state)
* 自定义RNN层
  * class NestedCell(keras.layers.Layer)
## 数据流水线(续)
* 确定标签
* 加载图片：tf.io.read_file(img_path)
* 格式化图片：tf.image.resize()
* 构建Dataset：image_ds=path_ds.map(load_and_preprocess_image)

