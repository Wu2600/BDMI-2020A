# 第十一节课：Tensorflow基础

## Keras

API：应用程序接口。Keras作为一个API，是一个只要规定了格式，就可以方便的运行神经网络

优点：API简单一致；创建神经网络的操作最少；提供了清晰的错误信息；有许多文档和开发者说明

### 预备知识

人工神经网络按照不同神经元之间的连接分为三种：

前馈网络（FNN）：神经元仅由之前的神经元决定

反馈网络：存在反馈，输出作为部分输入

记忆网络：输出有记忆

##### 常用神经网络举例：

卷积网络（CNN），一种前馈网络，具有计算快、可并行化的优点

循环网络（RNN），一种反馈网络。

### Keras简介

基于Tensorflow2实现的快速搭建深度神经网络的API

#### 核心概念——模型

Keras的核心数据结构

最简单的model类型是顺序模型（Sequential model）（指串接很多层的线性管道）

##### 层(Layer)

tf.keras.layers ：

keras内层对象的方法：flaten：压平；dropout随机置零

在创建层时，可以通过add_weight()方法增加权重，也可以在变量内设置其为不可变变量。

##### Model类

与Layer有相同的操作，但有如下区别：

1、会公开内置训练、评估和预测循环(model.fit()、model.evaluate()、model.predict())

2、会通过model.layers来公开其内部层的列表

3、有保存的API:（save()、save_weights()）

一般而言，Layer更接近层，而Model接近整个网络/模型，取决于对其的理解不同。

##### 优化器

如：optimizer基类,有SGD,RMSprop,Nadam等等

#### 使用流程

例程：已有数据集：mnis数据集，都是28x28的彩色图片

##### 1、定义网络

基于顺序结构，网络结构以一个栈的形式给出，一层接一层。

##### 2、编译网络

给定训练目标和优化算法

```python
model.compile(optimizer='adam',     #优化器
              loss='sparse_categorical_crossentropy',		#损失
              metrics=['accuracy'])				#指标
```

##### 3、网络训练

产生1000个符合input_shape的数据以及标签，开始迭代训练过程

```python
model.fit(x_train, y_train, batch_size = 64 , epochs=5 , validation_data = (x_val,y_val))
```

validation_data为验证集，即在训练的时候调整参数的参考

##### 4、评估网络

检查训练结果

```python
model.evaluate(x_test,  y_test, verbose=2)
```

##### 5、数据预测

model.predict(输入的数据)

##### 6、保存/载入网络

不推荐采用hdf5格式保存参数数据

##### 例程

```python
# 安装 TensorFlow
import tensorflow as tf

#载入并准备好 MNIST 数据集。将样本从整数转换为浮点数：

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

#将模型的各层堆叠起来，以搭建 tf.keras.Sequential 模型。为训练选择优化器和损失函数：

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

#训练并验证模型：

model.fit(x_train, y_train, epochs=5)

model.evaluate(x_test,  y_test, verbose=2)
```

### 补充知识：Python OOP

大部分都知道的，这里补充一些可能不熟悉的

#利用父类的构函：定义子类的时候，后面括号里放父类，直接把父类的init包括在自己的init里

#覆写父类的方法：重新写一遍

super() 超类，父类，可以用子对象调用父类已被覆盖的方法

super(Child,c).myMethod()

#### 自定义各种函数

##### 自定义损失函数

方法一：定义一个函数，当作loss的参数传进去，之后再用随便一个数据来对这个标签进行编码。注：该函数的参数需要有y_true和y_pred。

方法二：使用除以上两个参数之外的参数作为损失函数：则可以将tf.keras.losses.Loss类子类化，创建一个类后在call(self,y_true,y_pred)内计算模型的损失。

方法三：添加层来计算损失：

先用层（定义层的时候要调用自己的add_loss方法）计算输入（网络的输出）以及对应的输出（误差/损失），之后把输入和输出作为一个模型的输入和输出传进去，再调用模型的损失函数来计算损失。

##### 自定义层计算指标

同用层定义损失，在定义类的时候调用自己的add_metric方法。

#### 对数据集的处理方法

fit()的时候，validation_split参数可以保留百分之部分的数据用于验证。

##### tf.data

是一组实用的加载和预处理数据的工具。

如：

train_dataset = tf.data.Dataset.from_tensor_silces((x_train,y_train))

（这里以MNIST数据集为例）

这还可以直接传入fit()里。

这对于计算损失

##### 样本加权

class_weight = {

​	5:2.0

​	6:1.0

}（定义一个字典）

这样能让5对象更加重要

在fit()里的class_weight = class_weight传进去、

##### 回调

在训练时间内不同时间调用的对象，可用于：

训练期间在不同时间点进行验证

在超过一定准确率阈值时为模型设置检查点

在训练停滞不前时更改学习率或对顶层进行微调

在训练结束/超出特定性能阈值时进行通知

（代码看课件/手册，即查



### 顺序模型

顺序模型适用于一个普通堆栈图层，即每个图层只有一个输入和输出张量。

model = keras.Sequential(

[	

​	layers.Dense(x,activation = 'relu',name='layer1') #输出x个

]

)

注：这样创建之后，是不知道参数的形状的，需要输入一次

x = tf.ones((1,4))

y = model(x)

之后，model的参数形状才能被定下来。

或者也可以预先指定形状，在第一个层的Dense里用input_shape = ()，或者用model.add(keras.Input(shape=()))来指定参数形状

#### 迁移学习（Transfer learning）

要做分类任务，发现分的种类不够，已经训练了能分类1000种的参数。

方案一：（迁移学习，用了前人的知识）

假设有10层网络，保留/冻结前面九层，只训练最后一层来识别新的种类。

方案二：前面十层都不动，在最后再加一层，然后开始训练。

具体实现方法：

for layer in model.layers[:-1]:

​	layer.trainable = False

则实现了除了最后一层，全都不可训练，则有方法一的迁移训练。