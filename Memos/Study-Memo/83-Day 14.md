# 83 Day 14
### 课程总结：
这节课主要介绍了自动微分，深度学习(tensorflow)的框架以及自动语音识别概览，整体较为偏向于概念理解，具体的内容和延伸还有待自己去深度发掘与学习。
### 学习总结：

| 自动微分 | 对网络中每一步的算子都用链式法则，每次都代入求出导数值传到前面的神经元中，在计算完输出后，从计算的终点一个个往回计算，递归地找所有的计算节点，生成一个反过来的计算图。如此只需看局部就可以得到求导信息。特点：保存了过多的中间变量用于后续计算。改进：判断哪些在之后计算需要用到，不需要的求导出的数值就扔掉。使用TensorFlow 梯度带，在前向传播的过程之中, 就已经构建了反向计算图了 |
| :---------------: | :----------------------------------------------------------- |
| tensorflow的框架 | 深度学习框架是描述多层网络模型和模型训练推断的程序语言及工具类库，也即TensorFlow包，其同申明式语言（比如SQL）更类似。其包括：编程语言、解释器、编译器、动态计算图和静态计算图。框架的不同其实对应程序语言内部的不同设计。编译器也叫代码转换器比如代码跑在各种平台上，则需要有中间结果，再部署到各个平台上。Tensorflow 1.0 不是即时执行的, 2.0 是即时执行的; 1.0 是静态图的模式;2.0 版本是动态的运算图<br />编程模型的架构可分为三层，上层：训练层、推断库，中间层：python和c++接口，底层：网络层和设备层 |
| 语音识别原理及应用 | 语音识别的对象与本质：语音信号是声波，其可用波形图（时变信号）、频率图（FFT后）、时频谱（在波形图中拿很小的窗口，对小窗口进行傅里叶变换，再让小窗口不断向前，最后叠加在一起）来表示。本质上，v=f(t,h1)，h1为隐状态，表示人的口音等，w=F（v，h2）,h2是含有上下文的隐状态。其中v为语音信号，w为文字输出。<br />语音识别评判指标：词错误率（WER）错误率为对齐标准答案和识别结果，需要多少单个词的变换才能由结果变为标准答案。<br />具体的深度学习模型为谷歌CLDNN，结合CNN,LSTM和DNN：语音进来先卷积，再循环，再全连接。<br />CTC技术（Connectionist temporal classification）：流程(CTC折叠)：先生成一个序列，再合并相同的字符，扔掉空字符，最后合在一起，得到输出的单词。 |

### 训练代码：


