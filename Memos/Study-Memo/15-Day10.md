# [练习链接](https://github.com/wsp1911/BDMI_class_practice/tree/master/10)

# 计算图

包含一系列tensorflow操作的数据结构，代表操作之间流动的数据单位；灵活，效率高，容易优化

建图：tf.function

Tensorboard显示图

# 模块

对张量进行计算的函数

```python
mudule.trainable_variables	# 可训练变量
module.non_trainable_variables	# 不可训练
mudule.variables	# 所有变量
```

# 层

可重用的带参数的结构

模块的组合

# 模型

层的堆叠

## 存储和恢复

```python
chkp_path = "my_checkpoint"
checkpoint = tf.train.Checkpoint(model=my_model)
checkpoint.write(chkp_path)
```

```python
tf.train.list_variables(chkp_path)
```

```python
new_model = MySequentialModule()
new_checkpoint = tf.train.Checkpoint(model=new_model)
new_checkpoint.restore(path)
```

```python
# 保存整个模型
tf.saved_model.save(my_model, 'the_saved_model')
# 恢复的模型已经不是原来的类，在哪都能用，仍能完成前向运算
tf.saved_model.load("the saved_model")
```



# Tensorboard

```python
class Dense(tf.Module):
    def __init__(self, in_ftrs, out_ftrs, name=None):
        super().__init__(name=name)
        self.w = tf.Variable(tf.random.normal([in_ftrs, out_ftrs]), name="w")
        self.b = tf.Variable(tf.zeros([out_ftrs]), name='b')
    def __call__(self, x):
        y = tf.matmul(x, self.w)+self.b
        return tf.nn.sigmoid(y)
    
class SequentialModel(tf.Module):
    def __init__(self,name=None):
        super().__init__(name=name)
        
        self.dense1 = Dense(in_ftrs=3, out_ftrs=3)
        self.dense2 = Dense(in_ftrs=3, out_ftrs=1)
    @tf.function
    def __call__(self, x):
        x = self.dense1(x)
        return self.dense2(x)
```

```python
stamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
logdir = "logs/func/%s" % stamp
writer = tf.summary.create_file_writer(logdir)
model = SequentialModel(name="my_model")
tf.summary.trace_on(graph=True, profiler=True)
print(model(tf.constant([[2.0,2.0,2.0]])))
with writer.as_default():
    tf.summary.trace_export(
        name="my_func_trace",
        step=0,
        profiler_outdir=logdir)
```

注意需要对函数进行修饰

```python
@tf.function
```

# 训练过程

* 获取训练数据

* 定义模型

* 定义损失函数

* 运行训练数据，从目标值计算损失

* 计算损失的梯度，用优化器调整变量

* 结果评估

  

