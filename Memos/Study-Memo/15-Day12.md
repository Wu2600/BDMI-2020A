# [练习链接](https://github.com/wsp1911/BDMI_class_practice/tree/master/12)
# Keras模型保存和加载
## 保存和加载整个模型
* 架构配置
* 权重
* 编译信息
* 优化器及其状态
```python
model.save("my_model")
keras.models.load_model("my_model")
```
saved_model.pb:架构、配置
variables/: 权重
## 仅保存网络架构
```python
get_config()
from_config()
```
## 仅保存和加载模型权重
```python
# 内存中转移
get_weights()
set_weights()

layer2.set_weights(layer1.get_weights())

# 保存到磁盘
save_weights()
load_weights()

sequential = model.save_weights("ckpt")
load_status = sequential.load_weights("ckpt")
```
# 模型文件查看工具：netron
# MLP
多个Dense层网络，做图像分类时参数量过大
# 卷积网络
前馈网络，局部连接
参数少，运算快，并行化
## 基本结构
### 卷积层
卷积核运算等效于局部规则连接
### 池化层
卷积层后通常紧跟下采样层
下采样：缩小输出张量大小
* 最大池化
* 平均池化
### 归一化层
LCN
卷积后数字一般很大，正则化
目标：减去平均值，除以标准差
亮度不变性
池化层之后
## 发展
### LeNet-5
5x5卷积->2x2池化->5x5卷积->1x1卷积->1x1卷积
### AlexNet
## 应用
### 图像分类
### 人脸识别
### 对象检测
### 自动驾驶
# TensorFlow卷积网络
## Dense
超参数：神经元个数units
```python
tf.keras.layers.Dense(uints)
```
## Softmax
```python
tf.nn.softmax(logits)
```
## Conv
```python
tf.keras.layers.Conv2D(filters,kernel_size=(1,1),strides,padding="valid")
# filters: 卷积核数量
# kernel_size: 卷积核尺寸，为整数时各维度尺寸一致
```
## Pooling
pooing_type, window_shape, padding, strides
```python
tf.keras.layers.MaxPool3D(pool_size,strides,padding)

tf.keras.layers.AveragePooling3D(pool_size,strides,padding)
```
## Dropout
rate: 丢弃率
```python
tf.keras.layers.Dropout(rate)
```
# 数据集制作方法，tf.data
```python
# 读list, np.array
tf.data.Dataset.from_tensor_slices(data)

# 每次只返回一个样本
tf.data.Dataset.from_generator(func, args)
```