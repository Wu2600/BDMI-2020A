# 第十二周学习总结

### 本次课程的内容有：
- Keras模型保存和加载：整个模型/网络架构/模型权重
  - 保存整个模型：model.save()或tf.keras.models.save_model()，恢复tf.keras.models.load_model()
  - 保存架构：包括层和层的连接方式，初始化信息。get_config() & from_config(), eg. keras.Sequential.from_config(config)获得模型架构
  - 保存加载模型权重：
    内存中权重迁移：tf.keras.layers.Layer.get_weights(): 返回Numpy数组列表
    tf.keras.layers.Layer.set_weights(): 将模型权重设置为weight中的值
    权重保存到磁盘并加载回来：model.save_weights()，model.load_weights()（model为模型变量的名称）
  
- 卷积网络：
  - 模型参数：文件查看工具netron，网络层数、每层权重、输入输出
  - 基本结构：局部连接的顺序结构
  - 卷积核与卷积运算：卷积核数目一般选32/64等，采用非线性激活单元ReLU或Sigmoid
  - 每个卷积层后往往加入一个下采样层，下采样方法：maxpooling，averagepooling
  - 正则化层LCN,具有亮度不变性特点，在max-pooling之后

- Keras常用网络结构：
	- Dense：tk.keras.layers.Dense()，超参数是神经元个数units，后加softmax层（tf.nn.softmax）
	
  - CNN: tf.keras.layers.Conv2D()
	  filters(卷积核个数), kernel_size(卷积核大小), strides(行、列的步长)
	
	- Pooling：MaxPooling3D/AveragePooling3D, pool_size=(窗大小), padding, strides
	
	- 随机丢弃（Dropout Layer）：减少CNN过拟合，超参数keep_prob(rate, 丢弃率/保留率)，tf.keras.layers.Dropout()

- 图像处理应用：
	- Fashion MNIST数据集分类
	- 花图像分类：过拟合处理--增加训练样本，数据增强、dropout：随机将10%、20%、40%的神经元输出设置为0

- tf.data：tf.data.Dtaset表示序列元素，每个元素是一个基本训练样本，张量表示图像和对应标签
	- 从list/numpy array中读取：tf.data.Dataset.from_tensor_slices
	- 减少内存开销：from_generator(count, args = [25])，每次使用一部分数据进行计算
		- def count(stop):
		    i = 0
		    while i<stop:
		      yield i
		      i += 1
### 课程中遇到的问题：
暂无

### 课程收获：
学习了卷积神经网络的基本知识，了解了如何使用Keras库进行模型搭建，并对实例进行了实验；对如何处理过拟合情况产生了更多的了解。
