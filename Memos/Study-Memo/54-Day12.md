# 第十二节课：Tensorflow基础

#### Keras模型的保存和加载

训完了过几天再用

三种保存和加载的方式：

1、保存和加载整个模型

2、仅保存网络架构（不关心权重）

3、仅保存和加载模型的权重

##### 整个模型

包括：架构，权重值，编译信息，优化器及状态

model.save()或tf.keras.model.save_model()

reconsturcted_model = keras.models.load_model()

会创建在代码的同一目录内

##### 保存架构

只希望保存计算图，get_config()和from_config()

层的、顺序模型、函数式API模型 的 架构都可以这样保存和恢复。

##### 仅保存和加载模型的权重值

利用get_weights()和set_weights()来在不同对象之间复制权重，可以用于在内存中进行权重迁移。

用于将权重保存到磁盘里：model.save_weights()，加载回来：model.load_weights()

### 卷积网络

#### 优点

计算快，参数小，可以并行化。

p.s. 模型参数查看可以用工具netron:

https://github.com/lutzroeder/netron

#### 卷积网络基本结构

是一种前馈网络，但不同于全连接网络，卷积网络是局部连接，只和后面两个连。

卷积核一般选16、32、64等，之后依次进行张量点乘运算就可以了

有填充式：即在图像周围有填充一下预设的元素，一般填充0

三维卷积同理，是一个长方体形状的卷积核在不断移动。

##### 下采样层

每一个卷积层后面常常紧跟一个下采样层，用来缩小输出张量的大小。

方法：1、最大池化：采样取其中最大值

2、平均池化：取其中的平均值

##### 归一化层

在卷积运算之后输出张量的值一般会变大，此时就可以添加正则化层。

如LCN层：减去平均值，除以标准差，使得亮度不变，一般用在最大池化层之后。

#### 深度卷积网络应用

包括：图像分类、人脸识别（特征学习与特征工程）、对象检测、自动驾驶（各种道路上物体的检测）

为何使用卷积网络：如若使用多个Dense层网络（也称为多层感知机）进行图像分类，由于每个图片由RGB表示，则对200x200的图片，每个神经元就有200x200x3=120000个参数！这是不可接受的过大的参数量！

回顾训练的步骤：数据导入、数据预处理、构建模型（设置层+编译模型）、训练模型（输入数据，评估准确率，进行预测，验证预测结果）、使用模型

#### keras内的卷积网络调用

##### 在keras中用Conv2D表示2维卷积层

```python
# With `dilation_rate` as 2.
input_shape = (4, 28, 28, 3)
x = tf.random.normal(input_shape)
y = tf.keras.layers.Conv2D(
2, 3, activation='relu', dilation_rate=2, input_shape=input_shape[1:])(x)		#dilation_rate表示核膨胀率，即把卷积核变大，在元素之间填充0。
print(y.shape)			#y.shape = (4,24,24,2)
```

##### keras 池化层（以平均值池化为例，最大值池化同理）

```python
tf.keras.layers.AveragePooling3D(
    pool_size=(2, 2, 2), strides=None, padding='valid', data_format=None, 
)
```

pool_size是 一个三元组，表示输入的减少量，如(2,2,2)会在各个维度减半3D输入。

strides表示步长，是三元组。

##### 随机丢弃层(Dropout Layer)

意义：减少CNN过度拟合的问题

参数为keep_prob 丢弃率

对于所有的输入，有keep_prob的概率保留并且乘上1/keep_prob（为了前后总和大致相等），或者输出0（被丢弃了）

```python
tf.keras.layers.Dropout(
	rate,noise_shape=None,seed=None
)
```



课上之后举了一个识别服装的例程。

在评估准确率和测试准确率时的差距代表过拟合。过拟合是指机器学习模型在以前未见过的输入上的表现不如在训练数据上的表现。过拟合的模型会“记住”训练数据集中的噪声和细节，从而对模型在新数据上的表现产生负面影响。



在输出的时候附加一个softmax层，可以将输出转换为容易理解的概率。在最后验证预测结果部分，可以用柱状图来表示预测结果的准确与否。



keras模型进行了一些优化，可以同时对一批样本进行预测，具体操作方式为不管是一个样本还是一批样本，都将其添加到列表中。

即:img = (np.expand_dims(img,0))

#### 鲜花模型

这里举了一个识别鲜花模型为例。

可以通过配置数据集来提高性能。Dataset.cache()在第一个时代将图像从磁盘中加载后，将图像保留在内存中，而Dataset.prefetch()将创建一个Dataset从该数据集中预提取元素。

#### 避免过拟合的方法

##### 数据增强的随机变换方式

为了避免过拟合，可以采用数据增强的方式，即可以用**随机变换**（比如随机旋转、翻转等等）的方式对现有示例进行增强，这有助于展示数据的更多细节。

```python
data_augmentation = keras.Sequential(
[
layers.experimental.preprocessing.RandomFlip('horizontal',
	input_shape=(img_height,
	img_width,
	3)),
layers.experimental.preprocessing.RandomRotation(0.1),
layers.experimental.preprocessing.RandomZoom(0.1),
]
)
```

##### Dropout

同上所述。

#### 数据流水线

对数据进行预处理的API:tf.data，其功能包括：从不同的数据格式中读取数据、进行复杂的变换

其中tf.data.Dataset用于表示序列的元素，每个元素就是一个基本的训练样本，用一堆张量表示图像和对应的标签。

```python
#用tf.data读取list
dateset = tf.data.Dataset.from_tensor_slices([8,3,0,8,2,1])
tf.data.Dataset.from_tensor_slices((images,labels))		#图片与标签
```

tf.data.Dataset.from_generator可以减少内存开销，直接由生成函数生成数据。

```python
def count(stop):
    i = 0
    while i<stop:
        yield i
        i += 1
ds_counter = tf.data.Dataset.from_generator(count,args=[25])
```

还可以用高级的API批量读取文件夹里的图片（这个看课件）

tf.data.TextLineDataset读取txt

tf.data.experimental.make_csv_dataset读取表格数据

##### 数据增强

打乱数据：dataset.shuffle(buffer_size = 100)



对类别不平衡数据的处理：balanced_ds = tf.data.experimental.sample_from_datasets(

[negative_ds,positive_ds],[0.5,0.5]).batch(10)

)



在图片部分，有函数可以直接检查图片

```python
import IPython.display as display

for n in range(3):
    image_path = random.choice(all_image_paths)
    display.display(display.Image(image_path)
```

确定图片的标签：

先用列表列出可用的字符串形式的标签，再用字典的形式为每个标签分配索引：

{'daisy':0 , 'dandelion':1 , 'roses':2 , 'sunflowers':3 , 'tulips':4}

之后就可以创建一个列表，包含每个文件的标签索引了

```python
all_image_labels = [label_to_index[pathlib.Path(path),parent.name]
                   for path in all_iamge_paths]
```

在加载图片后要将其解码为图像的tensor：

```python
img_raw = tf.io.read_file(img_path)
img_tensor = tf.image.decode_image(img_raw,channels = 3)
img_final = tf.image.resize(img_tensor,[192,192])
img_final = img_final/255.0
#至此图片预处理完毕
```

（还有在加载和格式化图片的时候可以动态进行，每次show一下就行，具体参见课件

最后创建带标签的数据集：

```python
image_label_ds = tf.data.Dataset.zip((image_ds,label_ds))
```



