### WEEK 14

求导运算方法：数值微分、符号微分、自动微分

#### Tensorflow2 自动微分

每一步只是在局部做求导计算(直接使用数值传播) [类似于反向传播的方法]
反向传播的问题在于保存了很多的中间变量,不是很理想；
自动微分：在前向图的过程中顺便存下反向图的值；构建图的时候就知道哪些中间变量需要存，哪些在算完之后可以直接扔掉；
2.0即刻计算，编出网络就可以给出计算图；但是1.0并没有这个功能(1.0是静态图，只能编译之后打印？？)；

实际的服务器中， 模型及参数、训练、输入图像 可能都是分开的，但是计算图是共同使用的
Tensorflow上层: 训练库和推断库，部署最终的生成模型在不同的设备上
Tensorflow中间层: Python和C++接口，方便上层进行调用
Tensorflow底层: 网络层和设备层，Tensorflow可以灵活地运行在通过网络连接的不同设备上

深度学习框架：如果不做关于框架的深入研究，推荐 keras、tensorflow、Pytorch 等
顶层：Python/C++ 编写，中间层使用 IR 表示，底层再给到硬件上

##### 语音识别

语音识别的本质：F变换 w=F(v,h) 其中，v是输入的信号，h是隐藏变量，w是文字输出
评价指标：词错误率(详情见PPT13) 评价指标：[WER] 可能超过100%
纯深度学习：需要足够多的训练数据和足够的计算资源；端到端示例(PPT23)
谷歌CLDNN：结合了CNN、LSTM 和 DNN  对输入信号进行时间域卷积操作时候，再进行一次频率域的卷积操作以减少频谱的变化，之后再通过三层LSTM，最后再通过一层DNN；输入数据为以时间为下标的连续向量。

ASR-CTC技术：如何进行语音识别
导学：语音识别经典方法、连接主义的时间分类管理（就是循环时间网络）、端到端语音识别系统DeepSpeech2
CTC条件方程(重点关注PPT18)