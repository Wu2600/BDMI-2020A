# 第十周小结
---
## tensorflow2基础 
* 计算图的显示
  * 最开始 %load_ext tensorboard
  * 创建图前 @tf.function
  * 记录
    * writer=tf.summary.create_file_writer(logdir)
    * tf.summary.trace_on(graph=True,profiler=True)
    * ......计算过程
    * with writer.as_default():tf.summary.trace_export(name,step,profiler_outdir=logdir)
  * 可视化 %tensorboard --logdir logs/func
  
* 模块
  * class MyModule(tf.Module):

    ​        def __ init __ (self,name=None):super(). __ init __(name=name)...

    ​        def __ call __(self,x):...

* 层

  * class Dense(tf.Module):

    ​        def __ init __ (self,name=None):

    ​		def __ call __(self,x):...

* 模型

  * class SequentialModel(tf.Module):

    ​        def __ init __ (self,name=None):	self.dense1=Dense()....

    ​		def __ call __(self,x):...

* 动态决定张量维度：tf.Variable(tf.random.normal([x.shape[-1],self.out_features]))

* 检查点

  * checkpoint=tf.train.Checkpoint(model=my_model)
* checkpoint.write(chkp_path)
  
* 模型储存与恢复

  * tf.saved_model.save(my_model,"the saved model")
* new_model=tf.saved_model.load("the saved model")
  
* new_model不再为SequentialModel类，只能前向运算，不能训练
  
* 训练流程

  * 获取数据，定义模型：class MyModel(tf.Module):...

  * 定义损失函数：def loss(...):

  * 梯度下降：def train(model,x,y,learning_rate):

    ​                            with tf.GradientTape() as t:....

    ​							dw,db=t.gradient(...)
  
  *  记录损失函数的变化