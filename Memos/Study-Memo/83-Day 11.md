# 83 Day 11
### 课程总结：
这节课主要介绍了tensorflow中Keras的应用，keras是TensorFlow2中的一个应用程序接口（API），其相比TensorFlow更模块化，封装程度更大的程序库，它是基于TensorFlow2实现的，可以使用它快速搭建深度学习神经网络，此外keras还有易扩展，更灵活的特点，它的主要结构是模型，包括组织层的方式，以及层的连接关系和权重参数，其中最简单的模型是顺序模型，tf.keras.model.Sequencial，顺序网络是一种前馈网络，人工神经网络除了前馈还可以分为反馈和记忆网络。
### 学习总结：

| keras模型        | 前馈网络：神经元的输入只由前一层神经元的输出决定，例如（CNN）<br />反馈网络：部分神经元的输入还能由后某层神经元的输出决定，例如（RNN）<br />记忆网络：神经元不仅能够输出还能记忆其输出的值。 |
| :---------------: | :----------------------------------------------------------- |
| keras训练流程 | Keras的建模流程主要可分为如下几个步骤<br />定义网络，基于模型类别，网络结构以一个栈的形式给出，一层接一层。<br />编译网络，使用model.compile进行编译，主要是为了优化算法和增加训练时间，其中优化器（optimizer）有很多类，可以根据自己的需求选择，一般选择“adam”，该部还需定义损失函数及网络的训练目标（metrics，一般用’accuracy’）<br />训练网络，使用model.fit进行训练，定义训练集与验证集，批次大小和时代<br />评估网络，使用model.evaluate进行评估，定义测试集，查看模型在训练集以外的准确性数数据预测，使用model.predict进行给定的数据预测<br />保存载入网络，使用model.save（）或是models.save_model（）进行保存 |
| python面向对象编程 | 类的继承：定义子类时，使用class xxx（yyy）:来进行yyy这个父类的继承，若想改变某些__init__初始化，可以在子类的__init__中重新写，此外还可以使用super()来让子类重新获取父类全部的函数，即使在子类定义中关于某些父类的函数进行了复写。例如下面的代码块所示 |
| 迁移学习   | 在使用神经网络执行各种任务时，可以先参照前人已经证明有效的成熟模型，除了在其模型中进行改造，也可以直接保留其模型，只在其模型的最后一层自定义来识别或执行自己的数据集任务，例如已经有模型能够分类9种花，但是现在想多识别某种花，这样就能在冻结前端模型的时候，只训练最终的自定义层来更新网络，具体方法就是让网络中除了最终自定义层以外其余的层均不允许训练，可以使用`for layer in model.layers[:-1]: layer.trainable = False`来冻结模型中的层。 |

### 训练代码：

```python
class Parent:        # 定义父类
   def myMethod(self):
      print ('调用父类方法')

class Child(Parent): # 定义子类
   def myMethod(self):
      print ('调用子类方法')

c = Child()          # 子类实例
c.myMethod()         # 子类调用重写方法
super(Child,c).myMethod() #用子类对象调用父类已被覆盖的方法
```

