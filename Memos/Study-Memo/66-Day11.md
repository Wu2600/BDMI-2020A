# 第十一周小结
---
## tensorflow2-Keras 
* 网络结构：前馈（如FCN，MLP，CNN）、反馈（如RNN）、记忆网络

* Keras简介：基于tensorflow2的高级API

* Keras使用流程

  * 定义网络：tf.keras.models.Sequential([])
  * 编译网络：model.compile(optimizer,loss,metrics)
  * 网络训练：model.fit(data,labels,batch_size,epochs)
  * 评估网络：model.evaluate()
  * 数据预测：model.predict()
  * 保存、载入网络：model.save()/tf.keras.models.load_model()

* mnist数据集

  * mnist=tf.keras.datasets.mnist
  
* (x_train,y_train),(x_test,y_test)=mnist.load_data()
  
* fashion-mnist数据集：28*28彩色图像

* python面向对象编程

  * 类的定义、实例化、访问属性和方法

  * 类的继承

  * 调用已被覆盖的父类方法：super(Child,c).MyMethod()

* keras层和模型

  * 层class Linear(keras.layers.Layer)
  * 延迟创建权重：def build(self,input_shape):self.w=...
  * 层可递归组合
  * 模型：自带fit(),save(),compile()等外部接口

* 训练和评估进阶：model.compile()

  * 自定义损失函数

    * 方法一：def custom_loss(y_true,y_pred):

      ​               model.compile(loss=custom_loss(),...)
      
    * 方法二：class customMSE(keras.losses.Loss):

      ​                	def call(self,y_true,y_pred):

      ​               model.compile(loss=customMSE(),...)

  * 通过添加层计算损失，如class ActivityRegulationLayer()

     										  	def call(self,inputs):self.add_loss(...)	给损失函数添加正则项

* 顺序模型基础：每个图层只有一个输入和输出张量

  * 添加删除层：model.add(layers.Dense(...))	model.pop()
  
  * 打印模型摘要：model.summary()
  
  * 顺序模型功能提取：feature_extractor=keras.Model(inputs=initial_model.inputs,outputs=...)
  
  * 基于顺序模型的迁移学习：
  
    * 方案一：设置layer.trainable=False
  
    * 方案二：新初始化一个分类层model=keras.Sequential([base_model,layers.Dense(...)])
  
      ​           并设置base_model.trainable=False