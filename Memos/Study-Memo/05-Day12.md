# 课堂总结 LESSON12

## 0. 上节课内容延续

- 模型的保存与加载
  - 保存和加载整个模型（所有的信息）
    - model.save()或者tf.keras.models.save_model()
    - eg:model.save("my_model")这时会在相同路径下存一个名字为my_model的模型文件
  - 仅保存了网络的架构
    - 保存模型中有几层
    - get_config = 和from_o=config
    - configt = layer.get_config()
    - new_layer = keras.layers.Dense.from_confog（）
  - 仅保存和加载模型的权重
    - layer_1 = get_weights
    - layer_2  creat weights
    - 然后可以给layer2赋值layer1

## 一、卷积神经网络

1. 多层人工神经网络

2. 卷积核与卷积运算
   - 卷积是一种张量运算
3. 卷积层
4. 池化层（下采样法）
5. 归一化层

## 二、Dense

1. Neuron -> Layer
   - batch_size 会影响输出的shape，但不影响参数的shape
   - Dense的超参数：神经元个数U
   - softmax层：将得分logits计算出一个概率分布的向量
     - 所有输出数值为正，所有分量之和为1

## 三、Fashion Mnist 数据集实例

1. 利用Fashion Mnist实现分类器，用全连接Dense层搭建了Sequential模型

## 四、Flowers数据集CNN实例

1. CNN网络的搭建
2. 过拟合问题的情况：利用数据增强/dropout等方式来解决。
   - 数据增强的例子：将一张蒲公英的照片旋转，或者把蒲公英放置在各个位置
   - dropout应用于图层中，随机的放弃0.1/0.2...设置一个dropout层

## 五、tf.data

tf.data可以减少内存开销

写了一个count函数，在每次训练的时候只读取count返回的一个数据

